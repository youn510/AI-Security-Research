# [Review] Privacy & Security Concerns in Generative AI

## 1. Basic Info (기본 정보)
- **Title:** Privacy and Security Concerns in Generative AI: A Comprehensive Survey
- **Source:** IEEE Access (Open Access)
- **Date:** 2026.02.10

## 2. One-Line Summary (한 줄 요약)
> **"ChatGPT와 같은 생성형 AI 모델이 가진 고유한 취약점(탈옥, 환각, 데이터 유출)을 분류하고, 이를 방어하기 위한 기술적/윤리적 가이드라인을 제시한 논문"**

## 3. Key Findings (핵심 내용)
- **연구 방향:** 생성형 인공지능(GAI) 아키텍처, 다양한 생성 모델 유형, 실용적 적용 사례, 해당 분야의 최근 발전에 대한 논의
- **내용:** 생성형 AI의 개인정보 보호 및 보안 문제 (5가지 관점)

### 3.1. USER PERSPECTIVE  (사용자 관점)
- **개인 콘텐츠 조작**
- **신분 도용**
- **인증 과제**

### 3.2. ETHICAL PERSPECTIVE (윤리적 관점)
- **편향**
- **개발자 책임**
- **정책 입안자들**

### 3.3. REGULATORY AND LAW PERSPECTIVE (규제 및 법률 관점)
- **고전적 데이터 보호법**
- **지적 재산권**

### 3.4 TECHNOLOGICAL PERSPECTIVE (기술적 관점)
- **클래식 PPTS 대 PPDLS**
- **방어 기제**
- **모델 투명성**

### 3.5  INSTITUTIONAL PERSPECTIVE (제도적 관점)
- **데이터 처리 절차**
- **거버넌스 구조**
- **위험 완화 및 역전**
 
## 4. 결론 및 목표
- **사용자 생성 콘텐츠의 소유권 및 통제권:** 생성형 AI를 사용하는 사용자가 생성한 데이터의 소유권 및 통제권에 대한 명확한 지침이 부족하여
생성된 콘텐츠의 오용 및 무단 배포로 이어질 수 있음.
- **훈련 불안정성:** 생성 모델, 특히 VAE와 GAN을 훈련할 때 자주 발생하는 문제로, 훈련 과정 중 모델 매개변수 최적화가 어려워 수렴 속도가 느려지거나 수렴 자체가 실패하는 현상을 의미함.
- **해석 가능성 부족:** 모델이 학습한 잠재적 편향성이나 바람직하지 않은 특성에 대한 우려를 제기함.
- **적대적 공격:** 적대적 공격은 데이터 진위성 검증에 어려움을 초래하며, 특히 합성 데이터를 다른 모델 훈련에 활용하는 시나리오에서 두드러짐. 이는 생성 모델을 사용하는 AI 시스템에 대한 신뢰를 훼손할 수 있음.
- **규제 프레임워크 및 준수 과제**
- **데이터 프라이버시 위험 및 사용자 익명성**

## 4. My Insight (나의 생각 & 적용점)
- **새롭게 알게 된 점:** GAI의 위험성 및 여러 관점에서의 문제점이나 이를 보완하기 위한 해결책에 대해서 알게 되었음. 앞으로의 연구 및 개발 과정에서 이 논문과 같은 문제 또한 초래할 수 있음을 알게 되었음.
- **앞으로의 계획:** AI와 관련된 보안에 관한 관점들을 알아봤으니 앞으로는 보안에 조금 더 비중을 늘려 논문을 읽어볼 예정임.

---
*Reference: 2024_GenAI_Security_Privacy_Survey.pdf*
